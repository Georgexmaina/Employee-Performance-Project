{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86cqfImz8zsI"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pandas library is used to manipulate and read data in the notebook. I gave it variable pd.\n",
        "-Numpy library is used to work on arrays and numerical data. I gave it variable np.\n",
        "- Matplotlib and seaborn are both used for data visualization in the notebook. I gave them variable plt and sns respectively.\n"
      ],
      "metadata": {
        "id": "tX1ofcKTx-ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#connect notebook to drive and manipulatee the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uAOFetZu9D6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through the google colab library I used the function drive to give the notebook permission to access my files"
      ],
      "metadata": {
        "id": "Bge4n-o5zvjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Manipulate dataset as df\n",
        "df = pd.read_excel('/content/drive/My Drive/INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.xls')"
      ],
      "metadata": {
        "id": "U-1-sGCn9OV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using my given variable df to represent my dataset, I manipulated the dataset from my Google drive to the notebook."
      ],
      "metadata": {
        "id": "9Y0wWEtVzxvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA EXPLORATION**"
      ],
      "metadata": {
        "id": "SfLcfx8Z0CcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View first 10 rows\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "qlJpQ1pmB9A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Viewing the first 10 rows in my data using function head and the amount of rows to be shown.\n"
      ],
      "metadata": {
        "id": "G74cpcDe1Vcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Structure of the data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "w7V4qzSP11Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- By use of funtion info ,I gave a summary of the data (Checking amount of rows and columns ,data types of each column and the non_null count)."
      ],
      "metadata": {
        "id": "34lxzgsa17VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "lhAdPdgfC3A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using function shape ,I found that the data had 1200 rows and 28 columns"
      ],
      "metadata": {
        "id": "kzQf8lkc2Chv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#viewing the elements in target variable\n",
        "df['PerformanceRating'].unique()"
      ],
      "metadata": {
        "id": "C6lNCquKC-WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Function unique gave me the elements in performance rating column, all employees were either good (2), excellent (3) and outstanding (4)."
      ],
      "metadata": {
        "id": "z5XYWH0E3Dkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View datatypes in the variables\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "yqNA0et93zGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Viewing the data types in the variables and the data had 9 objects and 19 integers by the use of function dtypes."
      ],
      "metadata": {
        "id": "Fr8bH9os36W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for categorical and non categorical\n",
        "categorical_column = []\n",
        "non_categorical_column =[]\n",
        "for column in df.columns:\n",
        "  if df[column].dtype == 'object' or df[column].dtype == 'category':\n",
        "    categorical_column.append(column)\n",
        "  else:\n",
        "    non_categorical_column.append(column)\n",
        "print(\"Categorical column is:\")\n",
        "print(categorical_column)\n",
        "print(\"\\nnon_categorical column is:\")\n",
        "print(non_categorical_column)"
      ],
      "metadata": {
        "id": "zLyeSYR25bNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Grouping the datatypes to categorical and non_categorical columns for easy feature engineering and building my model.\n",
        "\n",
        "- I used the for loop function to group any column in my data with an object type of data to categorical column and else fuction took the rest of the columns to non_categorical column."
      ],
      "metadata": {
        "id": "Ly81_ggZ5jk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for nulls\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "EHctq8iPDRIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for nulls in the dataset using function isnull and function sum to find total nulls.\n",
        "- The data has 0 nulls hence clean"
      ],
      "metadata": {
        "id": "h26yM-cP4mAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "TU5UAUv5EkQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for duplicates in the data using function duplicated and sum function to get total duplicates.\n",
        "- Data had 0 duplicates hence clean."
      ],
      "metadata": {
        "id": "mEzy8idg47_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the statistical data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "rMuWufN346lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- View a summary of the statistics of the data using function describe."
      ],
      "metadata": {
        "id": "R5U98tq47SvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA CLEANING**"
      ],
      "metadata": {
        "id": "V3Vd4D9X7Ytq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data had no nulls and duplicates"
      ],
      "metadata": {
        "id": "4l7PESXY7dEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA VISUALIZATION**"
      ],
      "metadata": {
        "id": "M5iBanIf9OLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I came up with some insights on the employees performance rating  department wise.\n",
        "The performance rating was indicated as 2(Good), 3(excellent) and 4(outstanding)"
      ],
      "metadata": {
        "id": "9QEgM4ZG9SfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#relationship between employee department and performance rating\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='PerformanceRating',data=df)\n",
        "plt.title('Distribution of Employee Department and Performance Rating')"
      ],
      "metadata": {
        "id": "ehWhsAQy89PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the distribution of employee performance to employee department ,it is clear that there are less employees with outstanding rated performance compared with the average good rated performance in all departments apart from development and data science department.Most of the average performance comes from sales and research & development departments respectively.\n",
        "- In all departments most employees have excellent performance."
      ],
      "metadata": {
        "id": "Z1-mh_VfDiKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution between employee department and education level\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='EmpEducationLevel',data=df)\n",
        "plt.title('Distribution of Employee department and Employee education Level')"
      ],
      "metadata": {
        "id": "fWuvFJGtBONT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most employess are in all departments achieved a bachelor degree.\n",
        "- From the distribution, Research & development, Sales and Development department have the highest number of employees who are either below college level and college level which may lead to declined performance of the employees."
      ],
      "metadata": {
        "id": "GKW6qCUFLkwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#relationship between age and employee department\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='Age',data=df)\n",
        "plt.title('Distribution of Employee department and Age')"
      ],
      "metadata": {
        "id": "TyI7jDHU01vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As the histogram shows, in most departments employees are concetrated between the age of 24 and 32. The age reduces as the number of employees decrease."
      ],
      "metadata": {
        "id": "v5eHeL3BO_31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#relationship between education background and employee department\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='EducationBackground',data=df)\n",
        "plt.title('Distribution of Employee department and Employee education background')"
      ],
      "metadata": {
        "id": "eWThjx5B2g-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sales department has most employees who studied marketing but still had a high number of employees who studied life science and medical which are not related to the department.\n",
        "\n",
        "- Finance department also has a high number of employees in medical education background instead of marketing and might result to poor perfomance."
      ],
      "metadata": {
        "id": "hTwpr1guJ-Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Relationship between employee department and travel frequency\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='BusinessTravelFrequency',data=df)\n",
        "plt.title('Distribution of Employee department and Business Travel Frequency')"
      ],
      "metadata": {
        "id": "pTig3MPXJLEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is common that employees in all departments travel rarely. In addition ,Sales department had the highest number of declining performance by the employees and they rarely travel. This might be due to lack of motivation from the management."
      ],
      "metadata": {
        "id": "BFxHX4NVOiWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#relation between employee department and Experience years in Current Role\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='ExperienceYearsInCurrentRole',data=df)\n",
        "plt.title('Distribution of Employee department and Experience years in current role')"
      ],
      "metadata": {
        "id": "QzIG7g5eOYWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The distribution shows most employees have experience in their roles for between 0 to 3 years in most departments.\n",
        "- In 5 of the 6 departments, there is a significant number of employees who have no work experience in current roles with a total of 190 and most of them coming from development ,sales and Research& Development departments respectivly."
      ],
      "metadata": {
        "id": "FXlgYolFQ5PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Relation between employee department and attrition\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(x='EmpDepartment',hue='Attrition',data=df)\n",
        "plt.title('Distribution of Employee department and Attrition')"
      ],
      "metadata": {
        "id": "TdSfeNhZXiNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is a high number of employees with no attritions.\n",
        "- Employees in sales , development and research&Development departments have recorded over 50 attritions from their roles."
      ],
      "metadata": {
        "id": "aiSJ7Vkeay-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation  matrix and heatmap for the employee performance data\n",
        "#Select key features\n",
        "key_features = ['DistanceFromHome', 'EmpEducationLevel', 'EmpEnvironmentSatisfaction', 'EmpHourlyRate', 'EmpJobInvolvement', 'EmpJobLevel', 'EmpJobSatisfaction', 'EmpLastSalaryHikePercent', 'EmpRelationshipSatisfaction', 'TotalWorkExperienceInYears', 'TrainingTimesLastYear', 'EmpWorkLifeBalance', 'ExperienceYearsAtThisCompany', 'ExperienceYearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'PerformanceRating' ]\n",
        "#calculate correlation matrix\n",
        "correlation_matrix = df[key_features].corr()\n",
        "#heatmap\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H2uHgc11Ksrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The employee job level strongly relates to the total work experience in the employees' years (0.78)\n",
        "\n",
        "- The employees years of experience at the INX company strongly relates with years of experience in current role (0.76), years with the current manager(0.76), years of total work experience (0.63), years since last promotion  (0.62) and the employee job level (0.54).\n",
        "\n",
        "- The employees years with the current manager also strongly relates with years of employees experience in current role (0.73).\n",
        "\n",
        "- According to the employee performance rating, there is no significant correlation with other factors directly but the employee environment satisfaction seems to have a positive but weak correlation (0.4), the employee last salary hike percent by (0.33) and the employee work life balance (0.12)."
      ],
      "metadata": {
        "id": "vStZSdGZcvT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factors affecting performance**\n",
        "\n",
        "The top 3 factors affecting the employee performance are:\n",
        "- The employee environment satisfaction\n",
        "- The employee last salary hike percent\n",
        "- The employee work life balance"
      ],
      "metadata": {
        "id": "oPaNpFMtd2J6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MACHINE LEARNING**"
      ],
      "metadata": {
        "id": "l_TWcxEPeiqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature engineering**\n",
        "\n",
        "In feature engineering we transform the identified variables to features easier used in building models for predictive analysis"
      ],
      "metadata": {
        "id": "B-BLrUeHemkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding feature variables\n",
        "encoded_columns=['EmpNumber', 'Gender', 'EducationBackground', 'MaritalStatus', 'EmpDepartment', 'EmpJobRole', 'BusinessTravelFrequency', 'Attrition']\n",
        "#Library for encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for column in categorical_column:\n",
        "  df[column] = le.fit_transform(df[column])"
      ],
      "metadata": {
        "id": "xLROqK1R1u-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I encoded the feature variables by importing the LabelEncoder function from the Sklearn library and tranforming each column chosen to integers for easier functioning of the model."
      ],
      "metadata": {
        "id": "poBin-dGShlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View head\n",
        "df.head()"
      ],
      "metadata": {
        "id": "my2bcSlU36de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our table after encoding the columns"
      ],
      "metadata": {
        "id": "m24H7GAbTeKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Our target variable is performance rating and it is under classification type of data hence I used classification type of models to get the predictive outcome.\n",
        "- This classification models are Random Forest Classifier, Decision Tree Classifier, Support Vector Machine and K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "1zCt0s8e4kol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier (RFC)**"
      ],
      "metadata": {
        "id": "v5r_aek36ZrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for rdc and machine leaerning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score"
      ],
      "metadata": {
        "id": "dNgEnBGs3_TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import funtions from the sklearn library to train and split the data, to get the prediction accuracy, and to specify the model in use."
      ],
      "metadata": {
        "id": "Xl5OkHrgTqaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Give x and y variables\n",
        "x = df.drop('PerformanceRating',axis=1)\n",
        "y = df['PerformanceRating']\n",
        "#Split the variables\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "#Give model variable\n",
        "model = RandomForestClassifier()\n",
        "#Fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#Predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "#Check accuracy\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "id": "p8xBDL2t6uQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In RFC, I dropped my target variable and gave it a variable y in which it will be used for prediction.\n",
        "\n",
        "- Using the train_test_split function, I split the data to train and test, Training the data under 80% and test the 20% of the remaining data. I gave it a random number 42 for the data to be split in the same number as specified.\n",
        "\n",
        "- I gave RFC a variable model and used function fit to train the data under the model and also used the model on the test data with a variable y pred.\n",
        "\n",
        "- Finally, using function accuracy score, I viewed the result and printed out an accuracy of 95%"
      ],
      "metadata": {
        "id": "3r19VJPDUT9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier (DTC)**"
      ],
      "metadata": {
        "id": "FEeSdk5j-yGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraies for decision trees\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#Give x and y variables\n",
        "x = df.drop('PerformanceRating',axis=1)\n",
        "y = df['PerformanceRating']\n",
        "#Split the variables\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "#Give model variable\n",
        "model = DecisionTreeClassifier()\n",
        "#Fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#Predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "#Check accuracy\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "id": "2lC_4jCO-xov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (SVM)**"
      ],
      "metadata": {
        "id": "cCgG4iRk_H4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for svm\n",
        "from sklearn.svm import SVC\n",
        "#Give x and y variables\n",
        "x = df.drop('PerformanceRating',axis=1)\n",
        "y = df['PerformanceRating']\n",
        "#Split the variables\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "#Give model variable\n",
        "model = SVC()\n",
        "#Fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#Predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "#Check accuracy\n",
        "f1_score = f1_score(y_test,y_pred,average='weighted')\n",
        "print(\"F1_score:\",f1_score)"
      ],
      "metadata": {
        "id": "stVNJ1tp_HbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K_Nearest Neaighbors(KNN)**"
      ],
      "metadata": {
        "id": "MpNhqtVCBtd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "#Give x and y variables\n",
        "x = df.drop('PerformanceRating',axis=1)\n",
        "y = df['PerformanceRating']\n",
        "#Split the variables\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "#Give model variable\n",
        "model = SVC()\n",
        "#Fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#Predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "#Check accuracy\n",
        "f1_score = f1_score(y_test,y_pred, average='weighted')\n",
        "print(\"f1_score:\",f1_score)"
      ],
      "metadata": {
        "id": "6bk_PuzKB-Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning in decision tree classifier**"
      ],
      "metadata": {
        "id": "32RjvZ5WGSeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried hypertuning the dtc model to see if the performance can be improved and surpass the random forest performance."
      ],
      "metadata": {
        "id": "AXrO4QTuWwat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#librarries for hypertuning\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "4saGqJ1yIHPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the sklearn library, I imported the GridSearchCV function to identify the best parameters to tune our model."
      ],
      "metadata": {
        "id": "9ylwnM-dXGE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Param grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "#Create model variable\n",
        "dt = DecisionTreeClassifier()\n",
        "#Perform grid search\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "#Fit the grid search\n",
        "grid_search.fit(x_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "Vw5MasztGYF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The best parameter from the param grid were found by performing a grid search with our model decision trees being our estimator and having 5 folds in the cross validation.\n",
        "\n",
        "- Fit the grid search to my training data then use function best params to find the best parameters"
      ],
      "metadata": {
        "id": "1VIomggaXfGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Give variable to new model with best param\n",
        "best_model = DecisionTreeClassifier(**best_params)\n",
        "#Fit the model\n",
        "best_model.fit(x_train, y_train)\n",
        "#Predict the model\n",
        "y_pred_best = best_model.predict(x_test)\n",
        "#Check accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_best)\n",
        "print(\"Accuracy with best hyperparameters: \",accuracy)"
      ],
      "metadata": {
        "id": "0WemTZRUHDmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the best params in the model and I gave it a variable best model.\n",
        "\n",
        "- I passed the best model to fit the training data nad used it in the test data to predict my new performance.\n",
        "- I passed the accuracy score to the test and predict and printed out an accuracy of 92%"
      ],
      "metadata": {
        "id": "22CETVqnYY_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "92% from Decision Tree Classifier was not the best performing model hence Random forest Classifier gave me an accuracy of 95% making it the best model for prediction."
      ],
      "metadata": {
        "id": "lWoXZJ-RZP6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "The analysis reveals key insights into factors influencing employee performance at INX:\n",
        "\n",
        "- **Departmental Disparities**: Sales, R&D, and Development departments exhibit lower performance rates and higher attrition, potentially due to mismatched educational backgrounds and a high proportion of inexperienced employees.\n",
        "- **Limited Impact of Experience**: While experience in the current role correlates with overall tenure, it doesn't strongly influence performance ratings.\n",
        "- **Key Performance Drivers**: Employee environment satisfaction, salary hike percentage, and work-life balance emerge as the most significant factors directly linked to performance.\n",
        "\n",
        "**Recommendations**\n",
        "\n",
        "To enhance employee performance, INX should consider the following:\n",
        "\n",
        "- **Targeted Training and Development**: Implement department-specific training programs to bridge skill gaps, particularly for employees with non-relevant educational backgrounds.\n",
        "- **Enhance Employee Engagement**: Prioritize initiatives to improve work environment satisfaction, such as promoting collaboration, recognizing achievements, and providing opportunities for growth.\n",
        "- **Review Compensation and Benefits**: Conduct a thorough analysis of salary structures and benefits to ensure they are competitive and aligned with employee performance and contributions.\n",
        "\n",
        "- **Promote Work-Life Balance**: Implement flexible work arrangements and encourage managers to support a healthy work-life balance for their teams.\n",
        "- **Performance-Based Incentive**s: Consider linking salary hikes and promotions more directly to individual performance metrics.\n",
        "\n",
        "By addressing these areas, INX can foster a more engaged and productive workforce, ultimately leading to improved overall performance and reduced attrition."
      ],
      "metadata": {
        "id": "D5LhSAzT7PiR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrqFK_yO7XZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}